{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ca7207b-fe49-4d97-b1c5-ff37dfacb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python torchvision torch torchvision matplotlib pytesseract pyzbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e192e22c-e881-4ae7-9b7d-184f7fb4312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "# Specify the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Adjust the path if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b92be23-089c-4ef1-9b07-82978e964790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from pyzbar.pyzbar import decode  # Library for QR code and barcode detection\n",
    "\n",
    "# Load Faster R-CNN with ResNet50\n",
    "def load_faster_rcnn():\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Object Detection using Faster R-CNN\n",
    "def detect_objects(frame, model):\n",
    "    transform = T.Compose([T.ToTensor()])  # Convert the image to a tensor\n",
    "    img_tensor = transform(frame).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        predictions = model(img_tensor)\n",
    "\n",
    "    # Filter predictions with a threshold\n",
    "    detected_objects = []\n",
    "    threshold = 0.3  # Threshold for detection\n",
    "    for i, score in enumerate(predictions[0]['scores']):\n",
    "        if score > threshold:\n",
    "            box = predictions[0]['boxes'][i].cpu().numpy()\n",
    "            detected_objects.append({\n",
    "                \"class_id\": int(predictions[0]['labels'][i].cpu().numpy()),\n",
    "                \"score\": float(score.cpu().numpy()),\n",
    "                \"x\": int(box[0]),\n",
    "                \"y\": int(box[1]),\n",
    "                \"width\": int(box[2] - box[0]),\n",
    "                \"height\": int(box[3] - box[1])\n",
    "            })\n",
    "    return detected_objects\n",
    "\n",
    "# Text Recognition using Tesseract\n",
    "def extract_text(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray)\n",
    "    return text.strip()\n",
    "\n",
    "# QR Code and Barcode Detection using Pyzbar\n",
    "def extract_qr_barcode(frame):\n",
    "    barcodes = decode(frame)\n",
    "    barcode_data_list = []\n",
    "    for barcode in barcodes:\n",
    "        barcode_data = barcode.data.decode('utf-8')\n",
    "        barcode_type = barcode.type\n",
    "        barcode_data_list.append({\"data\": barcode_data, \"type\": barcode_type, \"rect\": barcode.rect})\n",
    "    return barcode_data_list\n",
    "\n",
    "# Analyze box structure based on size\n",
    "def analyze_box_structure(box):\n",
    "    # Assume some thresholds for perfect box structure\n",
    "    acceptable_width_range = (20, 200)  # Example width range in pixels\n",
    "    acceptable_height_range = (30, 300)  # Example height range in pixels\n",
    "\n",
    "    width = box[\"width\"]\n",
    "    height = box[\"height\"]\n",
    "\n",
    "    if (acceptable_width_range[0] <= width <= acceptable_width_range[1]) and (acceptable_height_range[0] <= height <= acceptable_height_range[1]):\n",
    "        return \"Good Structure\"\n",
    "    else:\n",
    "        return \"Bad Structure\"\n",
    "\n",
    "# Main function to capture video and process frames\n",
    "def main():\n",
    "    model = load_faster_rcnn()\n",
    "    cap = cv2.VideoCapture(0)  # Use the laptop's camera\n",
    "\n",
    "    frame_skip = 2  # Skip frames to reduce processing load\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Resize frame for better performance\n",
    "        frame = cv2.resize(frame, (640, 480))  # Reducing resolution to 640x480\n",
    "\n",
    "        # Skip frames to reduce load\n",
    "        frame_count += 1\n",
    "        if frame_count % frame_skip != 0:\n",
    "            continue  # Skip this frame\n",
    "\n",
    "        # Create a dictionary to store all results\n",
    "        results = {}\n",
    "\n",
    "        # Run object detection\n",
    "        detected_objects = detect_objects(frame, model)\n",
    "        results[\"detected_objects\"] = detected_objects\n",
    "\n",
    "        # Process detected objects for sorting\n",
    "        for obj in detected_objects:\n",
    "            # Measure size\n",
    "            size_info = {\n",
    "                \"height\": obj[\"height\"],\n",
    "                \"width\": obj[\"width\"]\n",
    "            }\n",
    "\n",
    "            # Analyze box structure\n",
    "            structure_status = analyze_box_structure(obj)\n",
    "\n",
    "            # Log results\n",
    "            print(f\"Detected Product: Size - Height: {size_info['height']}, Width: {size_info['width']}\")\n",
    "            print(f\"Box Structure: {structure_status}\")\n",
    "\n",
    "        # Run OCR\n",
    "        text = extract_text(frame)\n",
    "        results[\"text\"] = text\n",
    "\n",
    "        # Run QR/Barcode detection\n",
    "        qr_barcodes = extract_qr_barcode(frame)\n",
    "        results[\"qr_barcodes\"] = qr_barcodes\n",
    "\n",
    "        # Print the aggregated results for this frame in a readable format\n",
    "        print(\"\\n--- Detection Results ---\")\n",
    "        \n",
    "        # Object Detection Results\n",
    "        print(\"1. Object Detection:\")\n",
    "        if results[\"detected_objects\"]:\n",
    "            for idx, obj in enumerate(results[\"detected_objects\"], start=1):\n",
    "                print(f\"   Object {idx}: Class ID: {obj['class_id']}, Score: {obj['score']:.2f}, \"\n",
    "                      f\"Position: ({obj['x']}, {obj['y']}), Size: {obj['width']}x{obj['height']}\")\n",
    "        else:\n",
    "            print(\"   No objects detected.\")\n",
    "\n",
    "        # Text Recognition Results\n",
    "        print(\"\\n2. Text Recognition (OCR):\")\n",
    "        if results[\"text\"]:\n",
    "            print(f\"   Extracted Text: {results['text']}\")\n",
    "        else:\n",
    "            print(\"   No text detected.\")\n",
    "\n",
    "        # QR/Barcode Detection Results\n",
    "        print(\"\\n3. QR Code and Barcode Detection:\")\n",
    "        if results[\"qr_barcodes\"]:\n",
    "            for idx, qr in enumerate(results[\"qr_barcodes\"], start=1):\n",
    "                print(f\"   {idx}. Type: {qr['type']}, Data: {qr['data']}\")\n",
    "        else:\n",
    "            print(\"   No QR codes or barcodes detected.\")\n",
    "        \n",
    "        print(\"-------------------------\")\n",
    "\n",
    "        # Display results on the frame\n",
    "        # Draw detected objects\n",
    "        for obj in detected_objects:\n",
    "            x, y, w, h = obj[\"x\"], obj[\"y\"], obj[\"width\"], obj[\"height\"]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Draw QR/barcode detection area in red\n",
    "        for qr in qr_barcodes:\n",
    "            x, y, w, h = qr['rect'].left, qr['rect'].top, qr['rect'].width, qr['rect'].height\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red rectangle\n",
    "            cv2.putText(frame, f\"{qr['type']}: {qr['data']}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        # Show the processed frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dfa087-406c-47b1-a986-c298bcf3d12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405da19-f566-4139-bd6f-e38f6115181a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b98c7-db68-4fbb-ab7a-44d7b0e86c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
